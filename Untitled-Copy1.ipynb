{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import sample\n",
    "from scipy import ndimage\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit as inv_sigmoid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "\n",
    "        # n of nodes for input, hidden, output layers\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # weights\n",
    "        self.wih = np.random.normal(0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "    def train(self, input_list, target_list):\n",
    "        # NOTE: find a way to reutilise self.query() without returning final_output and being able to use the function vars.\n",
    "        # converts to a transposed 2D array, where it has a single column\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        targets = np.array(target_list, ndmin=2).T\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_outputs = np.dot(self.wih, inputs)\n",
    "        # calculate final signals from hidden layer\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        final_outputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate final signals from hidden layer\n",
    "\n",
    "\n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "\n",
    "        self.who += self.lr * np.dot(output_errors * final_outputs * (1 - final_outputs), np.transpose(hidden_outputs))\n",
    "\n",
    "        self.wih += self.lr * np.dot(hidden_errors * hidden_outputs * (1 - hidden_outputs), np.transpose(inputs))\n",
    "\n",
    "    def query(self, input_list):\n",
    "        # converts inputs to 2d array (2D image)\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        \n",
    "        #dot product multiplies each input node column for weight line with input array of columns, and returns an array\n",
    "        # where columns = n of nodes\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_outputs = np.dot(self.wih, inputs)\n",
    "        # calculate final signals from hidden layer\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        final_outputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate final signals from hidden layer\n",
    "\n",
    "        return final_outputs\n",
    "\n",
    "    def backquery(self, targets):\n",
    "        # reason: \"Note that logit(0) = -inf, logit(1) = inf, and logit(p) for p<0 or p>1 yields nan.\"\n",
    "        def adjust(x):\n",
    "            # (x - np.min(x)) / np.max(x) doesn't work for some reason???\n",
    "            x -= np.min(x)\n",
    "            x /= np.max(x)\n",
    "            x = x * 0+ 0.01\n",
    "            return x\n",
    "        \n",
    "        targets = np.array(targets, ndmin=2).T\n",
    "        \n",
    "        output_hidden = np.dot(self.who.T, inv_sigmoid(targets))\n",
    "        hidden_input = np.dot(self.wih.T, inv_sigmoid(adjust(output_hidden)))\n",
    "        \n",
    "        return adjust(hidden_input)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# ------ INPUT ------\n",
    "\n",
    "# n of nodes\n",
    "# inputnodes: total of pixels from database set (28x28)\n",
    "# hiddennodes: -\n",
    "# outputnodes: all possible outputs (numbers from 0 to 9)\n",
    "inputnodes, hiddennodes, outputnodes = 1, 10, 1000\n",
    "\n",
    "# learning rate\n",
    "lrate = 0.1\n",
    "\n",
    "# epoch: repetition of training session\n",
    "epoch = 5\n",
    "\n",
    "# - INITIALISATION --\n",
    "n = NeuralNetwork(inputnodes, hiddennodes, outputnodes, lrate)\n",
    "\n",
    "# ------ DATA -------\n",
    "\n",
    "numbers = sample(range(0, 500), 500)\n",
    "\n",
    "numbers[0] = 4\n",
    "print(numbers[0])\n",
    "print(numbers[0] * 2)\n",
    "targets = np.zeros(outputnodes) + 0.01\n",
    "targets[numbers[0] * 2 - 1] = 0.99\n",
    "print(np.argmax(targets))\n",
    "\n",
    "# ---- TRAINING ----\n",
    "\n",
    "for iteration in range(epoch):\n",
    "    for index in range(len(numbers)):\n",
    "        number = numbers[index]\n",
    "        targets = np.zeros(outputnodes) + 0.01\n",
    "        targets[numbers[index] * 2 - 1] = 0.99\n",
    "        # np.asfarray() is same as array() but automatically converts strings into numbers\n",
    "        # reshape tuple: [int(np.sqrt(len(values[1:])))] * 2\n",
    "        # arrays can be done math operations with, which apply to every individual value in the array\n",
    "        # inputs must NOT have value 0.00, because it can kill weights when multiplied with other weights (n * 0 = 0)\n",
    "        \n",
    "        n.train(number, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ---- TESTING -----\n",
    "\n",
    "print(np.argmax(n.query(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (200,784) and (28,28) not aligned: 784 (dim 1) != 28 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2584a90d10ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray_r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{a} | {b}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d2683416c9b8>\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, input_list)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m# calculate signals into hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mhidden_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwih\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;31m# calculate final signals from hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mhidden_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (200,784) and (28,28) not aligned: 784 (dim 1) != 28 (dim 0)"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "img = imageio.imread('data/handwriting/9.png', as_gray=True)\n",
    "print(len(img))\n",
    "img = (255 - img) / 255 * 0.99 + 0.01\n",
    "\n",
    "\n",
    "query = n.query(img)\n",
    "plt.imshow(img.reshape((28, 28)), cmap='gray_r')\n",
    "for a, b in enumerate(query): print(f'{a} | {b}')\n",
    "print()\n",
    "print(np.argmax(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18c018f8730>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = 0\n",
    "\n",
    "targets = np.zeros(outputnodes) + 0.01\n",
    "targets[label] = 0.99\n",
    "plt.imshow(n.backquery(targets).reshape(28, 28), cmap='gray_r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
