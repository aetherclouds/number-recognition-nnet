{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit as inv_sigmoid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "\n",
    "        # n of nodes for input, hidden, output layers\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # weights\n",
    "        self.wih = np.random.normal(0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "    def train(self, input_list, target_list):\n",
    "        # NOTE: find a way to reutilize self.query() without returning final_output and being able to use the function vars.\n",
    "        # converts to a transposed 2D array, where it has a single column\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        targets = np.array(target_list, ndmin=2).T\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate final signals from hidden layer\n",
    "        hidden_outputs = sigmoid(hidden_inputs)\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate final signals from hidden layer\n",
    "        final_outputs = sigmoid(final_inputs)\n",
    "        # and then finally, calculate the gap between expected vs actual results\n",
    "        output_errors = targets - final_outputs\n",
    "\n",
    "        # here's an attempt at visualizing. in the first matrix we lay down the respective hidden nodes and\n",
    "        # their connections with output nodes. we then multiply that with the amount of \"error\" in the output nodes\n",
    "        # under the precept that the hidden nodes with the most saying (weight) over the output node's output \n",
    "        # would also be responsible for the most error. \n",
    "        # basically, if output node 1 had a large error, then 20% of it will be blamed on hidden node 1,\n",
    "        # which has, say 25% of the total weight across all hidden nodes conected to output node 1.\n",
    "        #      O1   O2   O3   On\n",
    "        #    +----+----+----+      \n",
    "        # H1 |h1o1|h1o2|h1o3|       +--+\n",
    "        # H2 |h2o1|h2o2|h2o3|       |o1| O1\n",
    "        # H3 |h3o1|h3o2|h3o3|   x   |o2| O2\n",
    "        # H4 |h4o1|h4o2|h4o3|       |o3| O3\n",
    "        # H5 |h5o1|h5o2|h5o3|       +--+ On\n",
    "        # Hn +----+----+----+\n",
    "        # do note that in this case the hidden-output weight matrix is TRANSPOSED\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "\n",
    "        self.who += self.lr * np.dot(output_errors * final_outputs * (1 - final_outputs), np.transpose(hidden_outputs))\n",
    "        self.wih += self.lr * np.dot(hidden_errors * hidden_outputs * (1 - hidden_outputs), np.transpose(inputs))\n",
    "\n",
    "    def query(self, input_list):\n",
    "        # converts inputs to 2d array (2D image)\n",
    "        inputs = np.array(input_list, ndmin=2).T\n",
    "        \n",
    "        # dot product multiplies each input node column for weight line with input array of columns, and returns an array\n",
    "        # where columns = n of nodes\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate final signals from hidden layer\n",
    "        hidden_outputs = sigmoid(hidden_inputs)\n",
    "\n",
    "        # calculate signals into hidden layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate final signals from hidden layer\n",
    "        final_outputs = sigmoid(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "\n",
    "    def backquery(self, targets):\n",
    "        # we define adjust because \"Note that logit(0) = -inf, logit(1) = inf, and logit(p) for p<0 or p>1 yields nan.\"\n",
    "        def adjust(x):\n",
    "            # (x - np.min(x)) / np.max(x) doesn't work for some reason???\n",
    "            x -= np.min(x)\n",
    "            x /= np.max(x)\n",
    "            x = x * 0.98 + 0.01\n",
    "            return x\n",
    "        \n",
    "        targets = np.array(targets, ndmin=2).T\n",
    "        \n",
    "        output_hidden = np.dot(self.who.T, inv_sigmoid(targets))\n",
    "        hidden_input = np.dot(self.wih.T, inv_sigmoid(adjust(output_hidden)))\n",
    "        \n",
    "        return adjust(hidden_input)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------ INPUT ------\n",
    "\n",
    "# n of nodes\n",
    "# inputnodes: total of pixels from database set (28x28)\n",
    "# hiddennodes: -\n",
    "# outputnodes: all possible outputs (numbers from 0 to 9)\n",
    "inputnodes, hiddennodes, outputnodes = 784, 200, 10\n",
    "\n",
    "# learning rate\n",
    "lrate = 0.01\n",
    "\n",
    "# epoch: repetition of training session\n",
    "epoch = 1\n",
    "\n",
    "# - INITIALIZATION --\n",
    "n = NeuralNetwork(inputnodes, hiddennodes, outputnodes, lrate)\n",
    "\n",
    "# ------ DATA -------\n",
    "\n",
    "train_data = []\n",
    "\n",
    "f = open('../data/mnist_train.csv')\n",
    "for line in f:\n",
    "    train_data.append(line.split(','))    \n",
    "f.close()\n",
    "\n",
    "# ---- TRAINING ----\n",
    "\n",
    "for i in range(epoch):\n",
    "    for data in train_data:\n",
    "        # np.asfarray() is same as array() but automatically converts strings into numbers\n",
    "        # reshape tuple: [int(np.sqrt(len(values[1:])))] * 2\n",
    "        inputs = np.asfarray(data[1:])\n",
    "        # arrays can be done math operations with, which apply to every individual value in the array\n",
    "        # inputs must NOT have value 0.00, because it can kill weights when multiplied with other weights (n * 0 = 0)\n",
    "        inputs = (inputs / 255 * 0.99) + 0.01\n",
    "        \n",
    "        input_plus10 = ndimage.rotate(inputs.reshape(28, 28), 10, cval=0.01, reshape=False)\n",
    "        \n",
    "        input_minus10 = ndimage.rotate(inputs.reshape(28, 28), -10, cval=0.01, reshape=False)\n",
    "        \n",
    "\n",
    "        # create target 1D list with same amount of numbers as outputnodes\n",
    "        targets = np.zeros(outputnodes) + 0.01\n",
    "        # first items in value[] is the number label. the specified index is then the max output value (0.99)\n",
    "        # (differs from input list because the input can be 100%, but the network cannot be 100% sure on an output)\n",
    "        # values[] index must be kept at 0; dataset gives the number's label to the first value\n",
    "        targets[int(data[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        n.train(input_plus10.reshape(784), targets)\n",
    "        n.train(input_minus10.reshape(784), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9312\n"
     ]
    }
   ],
   "source": [
    "# ---- TESTING -----\n",
    "\n",
    "test_data = []\n",
    "f = open('../data/mnist_test.csv')\n",
    "for line in f:\n",
    "    test_data.append(f.readline().split(','))    \n",
    "f.close()\n",
    "\n",
    "\n",
    "scoreboard = []\n",
    "for data in test_data:\n",
    "    label = int(data[0])\n",
    "    # we \"normalize\" to avoid 0\n",
    "    results = n.query(np.asfarray(data[1:]) / 255 * 0.99 + 0.01)\n",
    "    if label == np.argmax(results):\n",
    "        scoreboard.append(1)\n",
    "    else:\n",
    "        scoreboard.append(0)\n",
    "print('accuracy:', (sum(scoreboard) / len(scoreboard)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kocze\\AppData\\Local\\Temp\\ipykernel_7596\\4001596825.py:4: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread('data/handwriting/9.png', as_gray=True)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'd:\\projects\\programming\\py\\nnet-n-recognition\\notebooks\\data\\handwriting\\9.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# ---- TEST YOUR OWN IMAGE ----\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimageio\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m img \u001b[39m=\u001b[39m imageio\u001b[39m.\u001b[39;49mimread(\u001b[39m'\u001b[39;49m\u001b[39mdata/handwriting/9.png\u001b[39;49m\u001b[39m'\u001b[39;49m, as_gray\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(img))\n\u001b[0;32m      6\u001b[0m img \u001b[39m=\u001b[39m (\u001b[39m255\u001b[39m \u001b[39m-\u001b[39m img) \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.99\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.01\u001b[39m\n",
      "File \u001b[1;32md:\\projects\\programming\\py\\nnet-n-recognition\\venv\\Lib\\site-packages\\imageio\\__init__.py:97\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[39mReads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     90\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mStarting with ImageIO v3 the behavior of this function will switch to that of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m iio.v3.imread. To keep the current behavior (and make this warning disappear)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m     95\u001b[0m )\n\u001b[1;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m imread_v2(uri, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\projects\\programming\\py\\nnet-n-recognition\\venv\\Lib\\site-packages\\imageio\\v2.py:226\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m imopen_args \u001b[39m=\u001b[39m decypher_format_arg(\u001b[39mformat\u001b[39m)\n\u001b[0;32m    224\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39;49m\u001b[39mri\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m    227\u001b[0m     result \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread(index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    229\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\projects\\programming\\py\\nnet-n-recognition\\venv\\Lib\\site-packages\\imageio\\core\\imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     request\u001b[39m.\u001b[39mformat_hint \u001b[39m=\u001b[39m format_hint\n\u001b[0;32m    112\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     request \u001b[39m=\u001b[39m Request(uri, io_mode, format_hint\u001b[39m=\u001b[39;49mformat_hint, extension\u001b[39m=\u001b[39;49mextension)\n\u001b[0;32m    115\u001b[0m source \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<bytes>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(uri, \u001b[39mbytes\u001b[39m) \u001b[39melse\u001b[39;00m uri\n\u001b[0;32m    117\u001b[0m \u001b[39m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\programming\\py\\nnet-n-recognition\\venv\\Lib\\site-packages\\imageio\\core\\request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Request.Mode: \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[39m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_uri(uri)\n\u001b[0;32m    249\u001b[0m \u001b[39m# Set extension\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39mif\u001b[39;00m extension \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\projects\\programming\\py\\nnet-n-recognition\\venv\\Lib\\site-packages\\imageio\\core\\request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39mif\u001b[39;00m is_read_request:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fn):\n\u001b[1;32m--> 407\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m fn)\n\u001b[0;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[39m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     dn \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(fn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'd:\\projects\\programming\\py\\nnet-n-recognition\\notebooks\\data\\handwriting\\9.png'"
     ]
    }
   ],
   "source": [
    "# ---- TEST YOUR OWN IMAGE ----\n",
    "import imageio\n",
    "\n",
    "img = imageio.imread('../data/handwriting.png', as_gray=True)\n",
    "print(len(img))\n",
    "img = (255 - img) / 255 * 0.99 + 0.01\n",
    "\n",
    "\n",
    "query = n.query(img)\n",
    "plt.imshow(img.reshape((28, 28)), cmap='gray_r')\n",
    "for a, b in enumerate(query): print(f'{a} | {b}')\n",
    "print()\n",
    "print(np.argmax(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2767526cb90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- \"BACKQUERYING\" ----\n",
    "# just 4 fun\n",
    "label = 0\n",
    "\n",
    "targets = np.zeros(outputnodes) + 0.01\n",
    "targets[label] = 0.99\n",
    "plt.imshow(n.backquery(targets).reshape(28, 28), cmap='gray_r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
